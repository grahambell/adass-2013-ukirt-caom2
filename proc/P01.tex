% This is the aspauthor.tex LaTeX file
% Copyright 2010, Astronomical Society of the Pacific Conference Series

\documentclass[11pt,twoside]{article}
\usepackage{asp2010}

\resetcounters

\bibliographystyle{asp2010}

\markboth{Bell et al.}{A New Archive of UKIRT Legacy Data at CADC}

\begin{document}

\title{A New Archive of UKIRT Legacy Data at CADC}
\author{Graham~S.~Bell,$^1$ Malcolm~J.~Currie,$^1$ Russell~O.~Redman,$^2$ Maren~Purves,$^1$ and Tim~Jenness$^{1,3}$
\affil{$^1$Joint~Astronomy~Centre, 660~N.~A`oh\={o}k\={u}~Place, Hilo, HI, 96720, U.S.A.}
\affil{$^2$Canadian Astronomy Data Centre, 5071 West Saanich Road, Victoria, BC, V9E 2M7, Canada}
\affil{$^3$Department of Astronomy, Cornell University, Ithaca, NY, 14853, U.S.A.}}

\begin{abstract}
We describe a  new archive of legacy data from the United Kingdom Infrared
Telescope (UKIRT) at the Canadian Astronomy
Data Centre (CADC) containing all available data
from the Cassegrain instruments.
The desire was to archive the raw data in as close to its original
format as possible, so where the data followed our current convention
of having a single data file per observation, it was archived
without alteration, except for minor fixes to headers of data in
FITS format to allow it to pass \texttt{fitsverify} and be accepted by CADC.
Some of the older data comprised multiple integrations in separate
files per observation, stored in either NDF or DST format. These
were placed inside HDS container files, and DST files were rearranged
into NDF format.
The metadata describing the observations is
ingested into the CAOM-2 repository via an
intermediate \texttt{MongoDB} header database, which will
also be used to guide the \texttt{ORAC-DR} pipeline
in generating reduced data products.
\end{abstract}

\section{Introduction}

A new archive of legacy data from the United Kingdom Infrared
Telescope (UKIRT) is being constructed at the Canadian Astronomy
Data Centre (CADC).
The archive contains data from UKIRT's Cassegrain instruments
--- listed in Table~\ref{p01:tab:instruments} ---
but excludes the Wide Field Camera (WFCAM),
since its data is already available in the WFCAM Science Archive
\citep{2008MNRAS.384..637H}
in Edinburgh.
The archive is to include raw and reduced data,
with the raw data
kept in as close to its original raw format as possible.

\begin{table}[!ht]
\caption{Instruments for which data are included in the new archive}
\smallskip
\begin{center}
\begin{tabular}{lcr@{ -- }lr@{ -- }l}
\tableline
\noalign{\smallskip}
Name & Type of Instrument & \multicolumn{2}{c}{Wavelength} & \multicolumn{2}{c}{Data Available} \\
     &                    & \multicolumn{2}{c}{[\micron]}  & \multicolumn{2}{c}{} \\
\noalign{\smallskip}
\tableline
\noalign{\smallskip}
CGS3     & spectrometer                   & \quad 10 & 20  & \, 1992 & 1997 \\
CGS4     & spectrometer                   &        1 & 5   & 1991 & 2009 \\
IRCAM3   & imager                         &        1 & 5   & 1994 & 2002 \\
Michelle & imager / spectrometer          &        8 & 25  & 2001 & 2004 \\
UFTI     & imager                         &        1 & 2.5 & 1998 & 2009 \\
UIST     & imager / spectrometer with IFU &        1 & 5   & 2002 & 2009 \\
\noalign{\smallskip}
\tableline
\end{tabular}
\end{center}
\label{p01:tab:instruments}
\end{table}

The archive is based on CAOM-2 \citep{2012ASPC..461..339D,P25_adassxxii},
the next generation of the Common Archive Observation Model
currently being developed at CADC.
This standardizes the core parts of the archive
between various \textit{collections}
and provides
a single ``advanced search'' interface for all of them.
UKIRT has been added to the repository
as a new collection.

At the start of this project, the raw data had already
been read from archive tapes stored at the
Joint Astronomy Centre and organized on disk.
Over the years data from UKIRT were stored on different tape
formats, read back, re-stored to different, more up-to-date
tape formats, and eventually pulled off the tapes to store on
disk. At this point not all of the tapes were readable so some
data are missing.
The process of transferring it to CADC,
reading the headers to generate the metadata
for CAOM-2 and running the data reduction
pipeline
is illustrated in Figure~\ref{p01:fig:flowchart}.

\begin{figure}[ht]
\includegraphics[scale=1.0]{P01_f1}
\caption{Diagram illustrating
the process of constructing the UKIRT legacy data archive.}
\label{p01:fig:flowchart}
\end{figure}

\section{Transfer of Data to CADC}
\label{p01:sec:etransfer}

The raw data were transferred to the archive at CADC
using the
Electronic Transfer system \citep{2005ASPC..347..647M}.
The files were copied to a directory in a
staging area where the system agent would
detect them and automate their transfer to the
archive, deleting them when this was complete.
Any files rejected by the agent were instead moved
to one of several \textit{reject} directories depending
on the cause for rejection.

As the files were staged for transfer,
filenames were standardized following our current convention.
In addition,
some minor adjustments were made,
depending on the format of the file.

\altsubsubsection*{FITS}

Some early raw data from UFTI were written in FITS format.
For transfer to the archive, these files were
required to pass
\texttt{fitsverify},
and this needed a few fixes to the headers.
One example was the removal of \texttt{Z} characters
previously used to indicate UTC in date headers.

\altsubsubsection*{NDF}

Much of the data were stored directly in
Starlink extensible N-dimensional Data Format
\citep[see for example,][]{P91_adassxxiii},
which itself is based on the
Starlink Hierarchical Data System (HDS).
In cases where an observation was recorded as
multiple integrations in separate files,
these were stored in a single HDS container file.

\altsubsubsection*{DST}

Data stored in the older Figaro format \citep{1993ASPC...52..219S}
--- which is also based on HDS ---
were converted to NDF.
As for raw NDF files, multiple integrations
were stored in HDS container files.

\section{Ingestion of Metadata into CAOM-2}

The metadata ingestion process was split into two stages.
First the headers were
read from the data files into an intermediate
\texttt{MongoDB} database.
Then for each observation an XML file was written
using the \texttt{pyCAOM2} library,
and sent to the CAOM-2 repository.
Both of these steps were quite time-consuming
and so separating them was very useful
as it allowed them to be developed
independently.

\texttt{MongoDB} was chosen for the intermediate database
as it allowed the
headers to be stored without prior knowledge of their structure
--- they were read in as Python dictionaries and
stored directly in the database.
It was also able easily to handle the large
volume of header data involved (3.8\,GiB).

\section{Data Reduction Pipeline}

The final stage is to run the \texttt{ORAC-DR} pipeline
\citep{1999ASPC..172...11E,2008AN....329..295C}
to generate reduced
data products.
This will use similar infrastructure at CADC as is already
used in the JCMT Science Archive
\citep{2011ASPC..442..203E}
and will reduce a complete night at once allowing
the pipeline to find the required calibrations.
\texttt{ORAC-DR} already been used for all of the instruments
involved except for CGS3.

We are currently testing the pipeline on a range of data,
including that predating its introduction.
Some header changes can be handled by updating the
\texttt{Astro::FITS::HdrTrans} module
\citep[section 2.2]{2008AN....329..295C}
which is used by \texttt{ORAC-DR} to convert
instrument specific header information into
a common set of generic headers.

In other cases the original headers are insufficient,
for example in allowing the pipeline to
select a data reduction recipe and determine the
grouping of the files.
Therefore the intermediate database of header information
can be re-used to identify
the groups of observations to be processed together and to infer
additional headers.
An example image reduced by this process is given in
Figure~\ref{p01:fig:hh111}.

\articlefigure[angle=270,scale=0.5]{P01_f2}{p01:fig:hh111}{Example image
of HH\,111 observed with IRCAM3 in 1997.  Separate integration files
have been merged into a single file per observation
(as described in Section~\ref{p01:sec:etransfer}) and the grouping
and additional headers were derived from the intermediate header
database, allowing the pipeline to process the data.
It was observed as part of a multi-year campaign
\citep{1998MNRAS.301L..10C}
studying the proper motions (measuring 265--461 km/s)
and variability of the knots in the protostellar outflows,
and found a number of faint features
which had previously not been detected.}

\section{Conclusions}

We have transferred 1.182 million files taken between 1991 and 2009 to
the CADC data archive, totaling 2.147\,TiB, and are currently generating
the metadata to enable them to be integrated into the CADC data
holdings.

\acknowledgements We would like to thank
Michael Tsutsumi for
retrieving the legacy data from tape,
which made this project conceivable.

\bibliography{P01}

\end{document}
